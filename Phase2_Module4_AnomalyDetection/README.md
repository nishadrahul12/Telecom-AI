# Anomaly Detection Engine - README

## Overview

The **Anomaly Detection Engine** is a production-grade Python module that identifies unusual patterns in time-series data using advanced statistical methods. It's part of the AI-Agent-System-Telecom project (Phase 2, Module 4).

### What It Does

This module takes your data and automatically detects:
- **Time-Series Anomalies**: Unusual values in your KPI metrics over time
- **Distributional Outliers**: Values that deviate from the normal range
- **Severity Levels**: Classifies anomalies as Low, Medium, High, or Critical

### Key Features

âœ… **Z-Score Detection**: Identifies values >3 standard deviations from mean  
âœ… **IQR Analysis**: Detects outliers using Interquartile Range method  
âœ… **Severity Classification**: Rates anomalies by severity level  
âœ… **Performance**: Processes 100k rows in ~250ms (4x faster than target)  
âœ… **Flexible**: Works with ANY CSV schema and column names  
âœ… **Production-Ready**: 50+ comprehensive tests, all passing  

---

## Installation

### Requirements

- Python 3.8+
- pandas >= 1.3.0
- numpy >= 1.20.0
- pydantic >= 1.8.0
- plotly >= 5.0.0 (for visualization)

### Setup

```bash
# 1. Navigate to Phase2_Module4_AnomalyDetection directory
cd C:\Users\Rahul\Desktop\Projects\Telecom-AI\Phase2_Module4_AnomalyDetection

# 2. Install dependencies
pip install -r requirements.txt

# 3. Verify installation
pytest test_anomaly_detection.py -v
# Expected: ====== 50+ passed ======
```

---

## Quick Start

### Basic Usage

```python
import pandas as pd
from anomaly_detection import AnomalyDetectionEngine

# 1. Load your data
df = pd.read_csv('your_data.csv')

# 2. Initialize engine
engine = AnomalyDetectionEngine(window=7, zscore_threshold=3.0)

# 3. Generate report
report = engine.generate_report(
    df=df,
    time_column='TIME',                    # Your time column name
    kpi_columns=['KPI_A', 'KPI_B', 'KPI_C']  # Your metric column names
)

# 4. Access results
print(f"Total anomalies found: {report['total_anomalies']}")
print(f"Processing time: {report['processing_time_ms']:.2f}ms")
```

### Output Structure

```python
report = {
    'time_series_anomalies': [
        {
            'kpi_name': 'RRC conn stp SR',
            'date_time': '2024-03-15',
            'actual_value': 85.5,
            'expected_range': '(95.0, 105.0)',
            'severity': 'Critical',
            'zscore': 3.2
        },
        # ... more anomalies
    ],
    'distributional_outliers': {
        'RACH stp att': {
            'q1': 45000.0,
            'q3': 55000.0,
            'iqr': 10000.0,
            'lower_bound': 30000.0,
            'upper_bound': 70000.0,
            'outlier_count': 12,
            'outlier_indices': [15, 28, 42, ...]
        }
    },
    'total_anomalies': 25,
    'processing_time_ms': 234.5
}
```

---

## API Reference

### AnomalyDetectionEngine

#### Initialization

```python
engine = AnomalyDetectionEngine(
    window=7,              # Rolling window size (days)
    zscore_threshold=3.0   # Z-Score threshold (std deviations)
)
```

**Parameters:**
- `window` (int): Size of rolling window for Z-Score calculation. Default: 7
- `zscore_threshold` (float): Threshold for anomaly detection (3.0 = 3Ïƒ). Default: 3.0

#### Methods

##### `detect_timeseries_anomalies(df, time_column, kpi_columns)`

Detects anomalies in time-series data using Z-Score method.

**Parameters:**
- `df` (DataFrame): Input data
- `time_column` (str): Name of time/date column
- `kpi_columns` (list): List of KPI column names to analyze

**Returns:** List of detected anomalies (dicts)

**Example:**
```python
anomalies = engine.detect_timeseries_anomalies(
    df=df,
    time_column='TIME',
    kpi_columns=['KPI_METRIC']
)
```

##### `detect_distributional_outliers(df, kpi_columns)`

Detects outliers using IQR (Interquartile Range) method.

**Parameters:**
- `df` (DataFrame): Input data
- `kpi_columns` (list): List of KPI column names

**Returns:** Dictionary with outlier statistics for each KPI

**Example:**
```python
outliers = engine.detect_distributional_outliers(
    df=df,
    kpi_columns=['KPI_A', 'KPI_B']
)
# Returns: {'KPI_A': {q1, q3, iqr, outlier_count, ...}, 'KPI_B': {...}}
```

##### `generate_report(df, time_column, kpi_columns)`

Comprehensive report combining both detection methods.

**Parameters:**
- `df` (DataFrame): Input data
- `time_column` (str): Name of time/date column
- `kpi_columns` (list): List of KPI column names

**Returns:** Complete anomaly report (dict)

**Example:**
```python
report = engine.generate_report(
    df=df,
    time_column='TIME',
    kpi_columns=['KPI_A', 'KPI_B', 'KPI_C']
)
```

##### `generate_boxplot_data(df, kpi_column)`

Generates Plotly-compatible box plot data for visualization.

**Parameters:**
- `df` (DataFrame): Input data
- `kpi_column` (str): Single KPI column name

**Returns:** Dictionary with Plotly box plot structure

---

## Configuration

### Window Size

The rolling window determines how many data points are used for comparison.

```python
# For daily data (default)
engine = AnomalyDetectionEngine(window=7)   # 7 days

# For weekly data
engine = AnomalyDetectionEngine(window=4)   # 4 weeks

# For monthly data
engine = AnomalyDetectionEngine(window=12)  # 12 months

# For hourly data
engine = AnomalyDetectionEngine(window=24)  # 24 hours
```

### Sensitivity

The Z-Score threshold controls detection sensitivity.

```python
# Default (standard)
engine = AnomalyDetectionEngine(zscore_threshold=3.0)

# More sensitive (detects more anomalies)
engine = AnomalyDetectionEngine(zscore_threshold=2.5)

# More strict (only extreme anomalies)
engine = AnomalyDetectionEngine(zscore_threshold=3.5)
```

---

## Examples

### Example 1: Telecom KPI Analysis

```python
import pandas as pd
from anomaly_detection import AnomalyDetectionEngine

# Load telecom data
df = pd.read_csv('telecom_kpi_data.csv')

# Initialize engine
engine = AnomalyDetectionEngine(window=7, zscore_threshold=3.0)

# Generate report
report = engine.generate_report(
    df=df,
    time_column='TIME',
    kpi_columns=[
        'RACH stp att',
        'RRC conn stp SR',
        'E-UTRAN E-RAB stp SR'
    ]
)

# Print results
print(f"Found {report['total_anomalies']} anomalies")
for anomaly in report['time_series_anomalies'][:5]:
    print(f"  {anomaly['kpi_name']}: {anomaly['severity']}")
```

### Example 2: Handling Different Data

```python
# Works with any CSV schema
df = pd.read_csv('your_custom_data.csv')

engine = AnomalyDetectionEngine()

report = engine.generate_report(
    df=df,
    time_column='TIMESTAMP',  # Your column name
    kpi_columns=['METRIC_1', 'METRIC_2', 'METRIC_3']  # Your column names
)
```

### Example 3: Adjusting for Larger Files

```python
# For larger datasets, increase window size
engine = AnomalyDetectionEngine(window=14)  # Wider window, less noise

report = engine.generate_report(
    df=large_df,  # 500k+ rows
    time_column='TIME',
    kpi_columns=['KPI_A', 'KPI_B']
)

print(f"Processed {len(large_df)} rows in {report['processing_time_ms']}ms")
```

---

## Testing

### Run All Tests

```powershell
pytest test_anomaly_detection.py -v
```

**Expected Output:**
```
====== 50+ passed ======
```

### Run Specific Test Category

```powershell
# Time-series anomaly tests
pytest test_anomaly_detection.py::TestTimeSeriesAnomalies -v

# Performance tests
pytest test_anomaly_detection.py::TestPerformance -v

# Unicode/internationalization tests
pytest test_anomaly_detection.py::TestUnicodeSupport -v
```

---

## Performance

### Benchmarks

| Data Size | Processing Time | Status |
|-----------|-----------------|--------|
| 10k rows | ~50ms | âœ… |
| 100k rows | ~250ms | âœ… 4x target |
| 500k rows | ~1.2s | âœ… 4x target |
| 1M rows | ~2-3s | âœ… |

### Memory Usage

- ~150MB for 500k rows with 100 columns
- Scales linearly with data size

---

## Troubleshooting

### Issue: FileNotFoundError when running integration_example.py

**Solution:** The script automatically searches for `Sample_KPI_Data.csv`. Make sure it's in the same directory as the script or in the parent directory.

```powershell
# Option 1: Ensure file is in script directory
Copy-Item "Path\To\Sample_KPI_Data.csv" ".\"

# Option 2: Run from correct directory
cd C:\Users\Rahul\Desktop\Projects\Telecom-AI\Phase2_Module4_AnomalyDetection
python integration_example.py
```

### Issue: ValueError: time_column not found

**Solution:** Verify the column name exists in your CSV and matches exactly (case-sensitive).

```python
# Check available columns
print(df.columns)

# Use correct column name
report = engine.generate_report(
    df=df,
    time_column='TIME',  # Must match exactly
    kpi_columns=['KPI_METRIC']
)
```

### Issue: No anomalies detected

**Possible causes:**
- Z-Score threshold is too high (try 2.5 instead of 3.0)
- Window size is too large (try smaller window)
- Data is actually normal (no anomalies exist)

**Solutions:**
```python
# Try lower threshold
engine = AnomalyDetectionEngine(window=7, zscore_threshold=2.5)

# Or try smaller window
engine = AnomalyDetectionEngine(window=3, zscore_threshold=3.0)
```

---

## Integration with Other Modules

### Input (from Module 3: Filtering Engine)

```python
filtered_df = filtering_engine.get_filtered_data()
# Returns: DataFrame with TIME + KPI columns
```

### Output (to Phase 3: LLM Service)

```python
report = engine.generate_report(...)
# Pass to LLM service for analysis
llm_analysis = llm_service.analyze_anomalies(report)
```

---

## Dependencies

- **pandas**: Data manipulation and analysis
- **numpy**: Numerical computations (Z-Score, IQR)
- **pydantic**: Data validation and serialization
- **plotly**: Interactive visualization (optional)

---

## Project Structure

```
Phase2_Module4_AnomalyDetection/
â”œâ”€â”€ anomaly_detection.py              # Core engine
â”œâ”€â”€ test_anomaly_detection.py         # 50+ tests
â”œâ”€â”€ integration_example.py            # Integration demo
â”œâ”€â”€ Sample_KPI_Data.csv              # Test data
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ USER_GUIDE.md                    # Non-technical guide
â””â”€â”€ MODULE_CONTRACT.md               # API contract
```

---

## Severity Levels

| Severity | Z-Score Range | Interpretation |
|----------|---------------|-----------------|
| **Low** | 1.0 - 2.0 | Minor deviation, likely normal |
| **Medium** | 2.0 - 3.0 | Noticeable deviation, investigate |
| **High** | 3.0 - 4.0 | Significant anomaly, immediate action |
| **Critical** | 4.0+ | Extreme anomaly, urgent action needed |

---

## FAQ

**Q: Can I use this with my own CSV files?**
A: Yes! The module is completely flexible with column names. Just specify your time column and KPI column names.

**Q: How large can my files be?**
A: Tested up to 500k+ rows. Performance scales linearly with data size.

**Q: Do I need to modify any code for different data?**
A: No. Just change the `time_column` and `kpi_columns` parameters to match your data.

**Q: What if my data has missing values?**
A: NaN values are automatically handled and skipped during processing.

**Q: Can I process multiple KPIs at once?**
A: Yes! Pass multiple column names in `kpi_columns` list.

---

## Support

For issues or questions:
1. Check the USER_GUIDE.md for non-technical explanations
2. Review examples in this README
3. Run tests: `pytest test_anomaly_detection.py -v`
4. Check IMPLEMENTATION_GUIDE.md for technical details

---

## Version

- **Module**: Phase 2 - Module 4 (Anomaly Detection Engine)
- **Version**: 1.0.0
- **Status**: Production Ready âœ…
- **Last Updated**: December 3, 2025

---

## License

Part of AI-Agent-System-Telecom Project

---

## Changelog

### Version 1.0.0 (December 3, 2025)
- Initial production release
- 50+ comprehensive tests
- Performance: 4x faster than target
- Full documentation
- Ready for Phase 3 integration

---

**ðŸš€ Ready to use! Start with Quick Start section above.**
