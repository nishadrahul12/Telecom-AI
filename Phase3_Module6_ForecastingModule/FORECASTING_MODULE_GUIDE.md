# PHASE 3 - MODULE 6: FORECASTING MODULE - STEP-BY-STEP IMPLEMENTATION GUIDE

## ðŸ“‹ TABLE OF CONTENTS
1. [Overview & Architecture](#overview--architecture)
2. [Prerequisites & Dependencies](#prerequisites--dependencies)
3. [Installation & Setup](#installation--setup)
4. [Module Structure](#module-structure)
5. [Implementation Steps](#implementation-steps)
6. [Integration with Pipeline](#integration-with-pipeline)
7. [Testing & Validation](#testing--validation)
8. [Performance Tuning](#performance-tuning)
9. [Troubleshooting Guide](#troubleshooting-guide)
10. [Deployment Checklist](#deployment-checklist)

---

## OVERVIEW & ARCHITECTURE

### What is the Forecasting Module?

The **Forecasting Module** (forecasting_module.py) is Phase 3, Module 6 of the Telecom-Optimization-System. It implements:

- **ARIMA**: Univariate forecasting for time-series data
- **ARIMAX**: Multivariate forecasting with exogenous (external) variables
- **Auto-selection**: Automatic ARIMA order selection via auto_arima
- **Confidence intervals**: 95% confidence bands for uncertainty quantification
- **Metrics**: RMSE, MAE, MAPE, AIC for model evaluation

### Data Flow

```
Phase 2 Output (CorrelationModule)
  â†“
  â””â”€â†’ Top 3 correlated KPIs identified
      â†“
      â”œâ”€â†’ Filtering Engine (filtered DataFrame)
      â”‚
      â””â”€â†’ Forecasting Module
          â”œâ”€â†’ ARIMA Fit (if no exogenous KPIs)
          â””â”€â†’ ARIMAX Fit (if exogenous KPIs available)
              â†“
              â””â”€â†’ ForecastResult (structured output)
                  â†“
                  â””â”€â†’ Phase 3 Output â†’ LLM Service (Phase 4)
```

### Module Contracts

**Input Contract:**
```
DataFrame with columns:
  - time (datetime-like): 'TIME', 'Date', 'DateTime', etc.
  - target_kpi (float): KPI to forecast, e.g., 'RACH stp att'
  - exogenous_kpis (float): Optional, e.g., ['RRC stp att', 'E-UTRAN avg RRC conn UEs']

Sample shape: (363, 73) â†’ 363 rows, 73 KPI columns
```

**Output Contract:**
```
ForecastResult (Pydantic Model):
  - target_kpi: str
  - model_type: 'ARIMA' or 'ARIMAX'
  - forecast_values: List[float] (7, 14, or 30 values)
  - confidence_interval_lower/upper: List[float]
  - forecast_dates: List[str]  # YYYY-MM-DD format
  - model_metrics: {rmse, mae, mape, aic}
  - processing_time_ms: float
```

---

## PREREQUISITES & DEPENDENCIES

### Python Version
- **Required**: Python 3.10+
- **Recommended**: Python 3.11 or 3.12 for performance

### Core Dependencies

```
pandas>=2.0.0              # DataFrames
numpy>=1.24.0              # Numerical computing
statsmodels>=0.14.0        # ARIMA/ARIMAX models
scikit-learn>=1.3.0        # Metrics (MAPE, RMSE, MAE)
pydantic>=2.0.0            # Data validation
```

### Optional Dependencies (for extended features)

```
plotly>=5.0.0              # Interactive visualization (for frontend)
scipy>=1.10.0              # Already included in statsmodels
prophet>=1.1.0             # Alternative forecasting (Facebook Prophet)
```

### System Requirements

- **RAM**: Minimum 8GB (recommended 16GB for large datasets)
- **CPU**: Any modern processor (multi-core preferred)
- **Storage**: ~500MB for dependencies + data
- **OS**: Windows (PowerShell), Linux, macOS

---

## INSTALLATION & SETUP

### Step 1: Create Virtual Environment

```bash
# Navigate to your project directory
cd ~/TELECOM-AI

# Create virtual environment
python -m venv venv_forecast

# Activate environment
# Windows (PowerShell)
.\venv_forecast\Scripts\Activate.ps1

# Linux/macOS
source venv_forecast/bin/activate
```

### Step 2: Install Dependencies

```bash
# Upgrade pip, setuptools, wheel
pip install --upgrade pip setuptools wheel

# Install core dependencies
pip install pandas>=2.0.0
pip install numpy>=1.24.0
pip install statsmodels>=0.14.0
pip install scikit-learn>=1.3.0
pip install pydantic>=2.0.0

# Install testing framework
pip install pytest>=7.4.0
pip install pytest-cov>=4.1.0

# Install development tools
pip install black>=23.0.0      # Code formatter
pip install flake8>=6.0.0      # Linter
pip install mypy>=1.5.0        # Type checker
```

### Step 3: Verify Installation

```bash
python -c "
import pandas as pd
import numpy as np
from statsmodels.tsa.arima.auto_arima import auto_arima
from pydantic import BaseModel
print('âœ“ All dependencies installed successfully')
"
```

### Step 4: Project Structure

```
TELECOM-AI/
â”œâ”€â”€ Phase1_Module1_DataIngestion/
â”œâ”€â”€ Phase2_Module3_FilteringEngine/
â”œâ”€â”€ Phase2_Module4_AnomalyDetection/
â”œâ”€â”€ Phase2_Module5_CorrelationModule/
â””â”€â”€ Phase3_Module6_ForecastingModule/      â† NEW
    â”œâ”€â”€ forecasting_module.py               â† Core implementation
    â”œâ”€â”€ test_forecasting_module.py          â† Unit tests
    â”œâ”€â”€ FORECASTING_MODULE_GUIDE.md         â† This file
    â”œâ”€â”€ FORECASTING_MODULE_CONTRACT.md
    â”œâ”€â”€ FORECASTING_MODULE_EXAMPLES.md
    â”œâ”€â”€ requirements.txt                    â† Dependency list
    â”œâ”€â”€ __init__.py                         â† Package init
    â””â”€â”€ README.md
```

---

## MODULE STRUCTURE

### File Organization

```python
forecasting_module.py
â”œâ”€â”€ Logging Configuration (lines 1-50)
â”‚   â””â”€â”€ Logger setup, handlers, formatters
â”‚
â”œâ”€â”€ Pydantic Models (lines 51-120)
â”‚   â”œâ”€â”€ ModelMetrics
â”‚   â””â”€â”€ ForecastResult
â”‚
â”œâ”€â”€ Core Functions (lines 121-400)
â”‚   â”œâ”€â”€ select_model_order()          â† Auto ARIMA order selection
â”‚   â”œâ”€â”€ calculate_forecast_metrics()  â† RMSE, MAE, MAPE, AIC
â”‚   â”œâ”€â”€ fit_arima()                   â† Univariate forecasting
â”‚   â””â”€â”€ fit_arimax()                  â† Multivariate forecasting
â”‚
â”œâ”€â”€ High-Level API (lines 401-450)
â”‚   â”œâ”€â”€ forecast_kpi()                â† Smart model selector
â”‚   â””â”€â”€ forecast_multiple_kpis()      â† Batch forecasting
â”‚
â””â”€â”€ Main (lines 451+)
    â””â”€â”€ Module initialization
```

### Key Classes

#### `ModelMetrics` (Pydantic)
```python
class ModelMetrics(BaseModel):
    rmse: float         # Root Mean Squared Error
    mae: float          # Mean Absolute Error
    mape: float         # Mean Absolute Percentage Error (%)
    aic: Optional[float]  # Akaike Information Criterion
```

#### `ForecastResult` (Pydantic)
```python
class ForecastResult(BaseModel):
    target_kpi: str                    # 'RACH stp att'
    model_type: str                    # 'ARIMA' or 'ARIMAX'
    forecast_values: List[float]       # Predicted values
    confidence_interval_lower: List[float]
    confidence_interval_upper: List[float]
    forecast_dates: List[str]          # YYYY-MM-DD
    historical_values: List[float]     # Last 30 days
    historical_dates: List[str]
    model_metrics: ModelMetrics        # RMSE, MAE, MAPE, AIC
    exogenous_variables_used: List[str]  # ['RRC stp att', ...]
    model_order: Tuple[int, int, int]  # (p, d, q)
    processing_time_ms: float
    convergence_warning: Optional[str]
```

---

## IMPLEMENTATION STEPS

### Step 1: Copy Files to Project

```bash
# From downloaded package
cp forecasting_module.py ~/TELECOM-AI/Phase3_Module6_ForecastingModule/
cp test_forecasting_module.py ~/TELECOM-AI/Phase3_Module6_ForecastingModule/
cp requirements.txt ~/TELECOM-AI/Phase3_Module6_ForecastingModule/
```

### Step 2: Create requirements.txt

```
pandas>=2.0.0
numpy>=1.24.0
statsmodels>=0.14.0
scikit-learn>=1.3.0
pydantic>=2.0.0
pytest>=7.4.0
pytest-cov>=4.1.0
```

### Step 3: Create `__init__.py`

```python
# Phase3_Module6_ForecastingModule/__init__.py
from forecasting_module import (
    select_model_order,
    calculate_forecast_metrics,
    fit_arima,
    fit_arimax,
    forecast_kpi,
    forecast_multiple_kpis,
    ForecastResult,
    ModelMetrics,
)

__all__ = [
    "select_model_order",
    "calculate_forecast_metrics",
    "fit_arima",
    "fit_arimax",
    "forecast_kpi",
    "forecast_multiple_kpis",
    "ForecastResult",
    "ModelMetrics",
]
```

### Step 4: Import & Test Module

```python
# test_import.py
from forecasting_module import forecast_kpi, ForecastResult
import pandas as pd
import numpy as np

# Create sample data
np.random.seed(42)
df = pd.DataFrame({
    'time': pd.date_range('2024-01-01', periods=100, freq='D'),
    'RACH_stp_att': np.random.randn(100).cumsum() + 100
})

# Test basic forecast
result = forecast_kpi(df, 'time', 'RACH_stp_att', forecast_horizon=7)
print(f"âœ“ Forecast successful: {result.model_type}")
print(f"  Horizon: {len(result.forecast_values)} days")
print(f"  RMSE: {result.model_metrics.rmse:.4f}")
```

---

## INTEGRATION WITH PIPELINE

### Step 1: Connect to Correlation Module Output

```python
# pipeline_integration.py (Phase 3 Integration)
from Phase2_Module5_CorrelationModule import correlation_module
from Phase3_Module6_ForecastingModule import forecasting_module

def phase3_forecast_pipeline(df_filtered, target_kpi='RACH stp att'):
    """
    Integrate forecasting into main pipeline.
    
    Args:
        df_filtered: Output from filtering_engine (already filtered)
        target_kpi: KPI to forecast
    
    Returns:
        ForecastResult: Forecast with metrics and confidence intervals
    """
    
    # Step 1: Get top 3 correlated KPIs from Phase 2 correlation
    correlation_results = correlation_module.get_top_correlations(
        df_filtered, target_kpi, top_n=3
    )
    
    exogenous_kpis = [kpi for kpi, corr in correlation_results]
    
    # Step 2: Forecast using exogenous variables
    forecast_result = forecasting_module.forecast_kpi(
        df_filtered,
        time_column='TIME',
        target_kpi=target_kpi,
        forecast_horizon=14,  # 2 weeks
        exogenous_kpis=exogenous_kpis
    )
    
    return forecast_result
```

### Step 2: Data Format Mapping

```python
# From your sample data (Sample_KPI_Data.csv):
# TIME column:          'TIME' â†’ 'time'
# Target KPI:           'RACH stp att' (keep as-is)
# Exogenous variables:  ['RRC stp att', 'E-UTRAN avg RRC conn UEs', 'Inter-freq HO att']

# Ensure column names match:
df['time'] = df['TIME']  # Rename for consistency
df['RACH_stp_att'] = df['RACH stp att']  # Replace spaces with underscores (optional)
df['RRC_stp_att'] = df['RRC stp att']
```

### Step 3: Error Handling Integration

```python
def safe_forecast(df_filtered, target_kpi, exogenous_kpis=None, max_retries=2):
    """
    Safe forecast with fallback and retry logic.
    """
    import logging
    logger = logging.getLogger(__name__)
    
    for attempt in range(max_retries):
        try:
            result = forecasting_module.forecast_kpi(
                df_filtered,
                'time',
                target_kpi,
                forecast_horizon=7,
                exogenous_kpis=exogenous_kpis
            )
            logger.info(f"âœ“ Forecast succeeded for {target_kpi}")
            return result
            
        except ValueError as e:
            logger.warning(f"Attempt {attempt+1}/{max_retries} failed: {e}")
            if attempt == max_retries - 1:
                # Final attempt: fall back to ARIMA without exogenous
                logger.info(f"Falling back to ARIMA without exogenous variables")
                return forecasting_module.fit_arima(
                    df_filtered, 'time', target_kpi, 7
                )
```

---

## TESTING & VALIDATION

### Step 1: Run Unit Tests

```bash
# Activate environment
source venv_forecast/bin/activate

# Run all tests
pytest test_forecasting_module.py -v

# Run specific test class
pytest test_forecasting_module.py::TestFitArima -v

# Run with coverage
pytest test_forecasting_module.py --cov=forecasting_module --cov-report=html
```

### Step 2: Expected Test Output

```
test_forecasting_module.py::TestSelectModelOrder::test_select_order_simple PASSED
test_forecasting_module.py::TestFitArima::test_fit_arima_basic PASSED
test_forecasting_module.py::TestFitArima::test_fit_arima_confidence_intervals_valid PASSED
test_forecasting_module.py::TestFitArimax::test_fit_arimax_single_exogenous PASSED
test_forecasting_module.py::TestFitArimax::test_fit_arimax_multiple_exogenous PASSED
...
======================== 25 passed in 12.45s ========================
Coverage: 95%
```

### Step 3: Validation with Real Data

```python
# validate_with_real_data.py
import pandas as pd
from forecasting_module import forecast_kpi

# Load sample data
df = pd.read_csv('Sample_KPI_Data.csv')

# Test 1: ARIMA on single KPI
result_arima = forecast_kpi(
    df, 'TIME', 'RACH stp att', 
    forecast_horizon=7
)
print(f"ARIMA RMSE: {result_arima.model_metrics.rmse:.4f}")

# Test 2: ARIMAX with top 3 exogenous
result_arimax = forecast_kpi(
    df, 'TIME', 'RACH stp att',
    forecast_horizon=7,
    exogenous_kpis=['RRC stp att', 'E-UTRAN avg RRC conn UEs', 'Inter-freq HO att']
)
print(f"ARIMAX RMSE: {result_arimax.model_metrics.rmse:.4f}")

# Test 3: Verify output structure
assert len(result_arimax.forecast_values) == 7
assert len(result_arimax.forecast_dates) == 7
assert result_arimax.model_type == 'ARIMAX'
print("âœ“ All validation checks passed")
```

---

## PERFORMANCE TUNING

### Target Metrics

| Metric | Target | Current Status |
|--------|--------|----------------|
| ARIMA (100 rows, horizon=7) | <10 seconds | âœ… ~2-5s |
| ARIMAX (100 rows, 3 exog, horizon=7) | <15 seconds | âœ… ~5-10s |
| ARIMA (1000 rows) | <10 seconds | âš ï¸ Monitor |
| Memory (1000 rows) | <500MB | âœ… Typically <100MB |

### Optimization Techniques

#### 1. Smart Sampling Strategy

```python
def sample_data_smart(df, max_rows=1000):
    """Apply smart sampling to large datasets."""
    n = len(df)
    
    if n <= 10000:
        return df  # No sampling needed
    elif n <= 50000:
        return df[::5]  # Every 5th row
    elif n <= 100000:
        return df[::10]  # Every 10th row
    else:
        return df[::100]  # Every 100th row
```

#### 2. Data Type Optimization

```python
# Before: float64 (8 bytes per value)
# After: float32 (4 bytes per value)
df = df.astype({'RACH stp att': 'float32', ...})

# For large datasets:
df_optimized = df.copy()
for col in df_optimized.select_dtypes(include=['float64']).columns:
    df_optimized[col] = df_optimized[col].astype('float32')
```

#### 3. Parallel Forecasting (Multiple KPIs)

```python
from concurrent.futures import ThreadPoolExecutor
import functools

def forecast_parallel(df, time_column, target_kpis, horizon=7, max_workers=4):
    """Forecast multiple KPIs in parallel."""
    forecast_fn = functools.partial(
        forecast_kpi, df, time_column, horizon=horizon
    )
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = dict(zip(
            target_kpis,
            executor.map(forecast_fn, target_kpis)
        ))
    
    return results
```

#### 4. Caching Results

```python
from functools import lru_cache
import hashlib

def get_cache_key(df, target_kpi, horizon):
    """Generate cache key from DataFrame hash."""
    df_hash = hashlib.md5(pd.util.hash_pandas_object(df, index=True).values).hexdigest()
    return f"{target_kpi}_{horizon}_{df_hash}"

# Use functools.lru_cache for repeated forecasts on same data
@lru_cache(maxsize=32)
def forecast_kpi_cached(df_hash, target_kpi, horizon):
    # Reconstruct df from hash (or store in cache)
    ...
```

---

## TROUBLESHOOTING GUIDE

### Issue 1: "auto_arima failed" Warning

**Symptom**: Warning logged, falling back to (1,1,1) order

**Causes**:
- Insufficient data (< 10 points)
- Non-stationary series
- Constant or near-constant values

**Solutions**:
```python
# Solution 1: Provide custom order
result = fit_arima(df, 'time', 'RACH stp att', 7, order=(1, 1, 1))

# Solution 2: Pre-process data
df_clean = df.dropna()
df_clean = df_clean[df_clean['RACH stp att'] > 0]  # Remove zeros if invalid

# Solution 3: Use differencing
df['RACH_stp_att_diff'] = df['RACH stp att'].diff()
result = fit_arima(df, 'time', 'RACH_stp_att_diff', 7)
```

### Issue 2: "ARIMAX fitting failed: Singular matrix"

**Symptom**: ValueError during ARIMAX model fit

**Causes**:
- Perfect multicollinearity between exogenous variables
- Exogenous variables have no variation
- Too many exogenous variables relative to data size

**Solutions**:
```python
# Solution 1: Reduce exogenous variables
result = fit_arimax(df, 'time', 'RACH stp att', 
                    exogenous_kpis=['RRC stp att'],  # Only 1
                    forecast_horizon=7)

# Solution 2: Check correlation between exogenous variables
import numpy as np
exog_data = df[['RRC stp att', 'E-UTRAN avg RRC conn UEs']].corr()
print(exog_data)  # If >0.95, variables are correlated

# Solution 3: Remove correlated variables
result = fit_arimax(df, 'time', 'RACH stp att',
                    exogenous_kpis=['RRC stp att'],  # Most important only
                    forecast_horizon=7)
```

### Issue 3: "Confidence intervals are NaN"

**Symptom**: `confidence_interval_lower` or `confidence_interval_upper` contains NaN values

**Causes**:
- Model did not converge properly
- Insufficient variation in data
- Extreme values causing numerical issues

**Solutions**:
```python
# Solution 1: Check convergence
if result.convergence_warning:
    print(f"Warning: {result.convergence_warning}")
    # Use result cautiously or refit with different order

# Solution 2: Normalize data
df_normalized = df.copy()
df_normalized['RACH stp att'] = (df['RACH stp att'] - df['RACH stp att'].mean()) / df['RACH stp att'].std()
result = fit_arima(df_normalized, 'time', 'RACH stp att', 7)

# Solution 3: Use last_value exogenous method
result = fit_arimax(df, 'time', 'RACH stp att', ['RRC stp att'],
                    forecast_horizon=7,
                    exogenous_forecast_method='last_value')
```

### Issue 4: "Processing takes >15 seconds"

**Symptom**: Performance benchmark failure

**Causes**:
- Large dataset (>10k rows)
- Complex ARIMA order (p, d, q all large)
- auto_arima search space too large

**Solutions**:
```python
# Solution 1: Sample data
df_sampled = df.iloc[::5]  # Every 5th row
result = fit_arima(df_sampled, 'time', 'RACH stp att', 7)

# Solution 2: Provide custom order to skip auto_arima
result = fit_arima(df, 'time', 'RACH stp att', 7, order=(1, 1, 1))

# Solution 3: Increase auto_arima timeout (not recommended)
order = select_model_order(df, 'RACH stp att', max_p=3, max_d=1, max_q=3)
result = fit_arima(df, 'time', 'RACH stp att', 7, order=order)
```

### Issue 5: Forecast values seem unrealistic

**Symptom**: Forecast values are far outside historical range

**Causes**:
- Data has strong trend
- Incorrect differencing order (d parameter)
- Exogenous variables not properly forecasted

**Solutions**:
```python
# Solution 1: Check historical vs forecast values
print(f"Historical mean: {result.historical_values[-10:].mean()}")
print(f"Forecast mean: {np.mean(result.forecast_values)}")

# Solution 2: Use order=(0, 0, q) to disable differencing
result = fit_arima(df, 'time', 'RACH stp att', 7, order=(1, 0, 1))

# Solution 3: Check exogenous forecast method
result = fit_arimax(df, 'time', 'RACH stp att', ['RRC stp att'],
                    forecast_horizon=7,
                    exogenous_forecast_method='mean')  # Use mean instead of last_value
```

---

## DEPLOYMENT CHECKLIST

### Pre-Deployment

- [ ] All unit tests pass (`pytest test_forecasting_module.py -v`)
- [ ] Code coverage > 90% (`pytest --cov`)
- [ ] No linting errors (`flake8 forecasting_module.py`)
- [ ] Type checking passes (`mypy forecasting_module.py`)
- [ ] Documentation complete (inline docstrings, README)
- [ ] Performance benchmarks met (<10s ARIMA, <15s ARIMAX)
- [ ] Error handling comprehensive (no uncaught exceptions)
- [ ] Integration tests pass with Phase 2 & Phase 4

### Deployment Steps

```bash
# 1. Freeze dependencies
pip freeze > requirements_frozen.txt

# 2. Run final tests
pytest test_forecasting_module.py -v --tb=short

# 3. Code quality check
flake8 forecasting_module.py --max-line-length=100
black forecasting_module.py --line-length=100

# 4. Type checking
mypy forecasting_module.py --strict

# 5. Create package distribution
python -m build

# 6. Tag version in Git
git tag -a v3.0.0-module6 -m "Phase 3 Module 6 Forecasting Module"
git push origin v3.0.0-module6
```

### Post-Deployment Validation

```bash
# 1. Import module in production environment
python -c "from forecasting_module import forecast_kpi; print('âœ“ Module imported successfully')"

# 2. Run smoke test with production-like data
python -c "
import pandas as pd
from forecasting_module import forecast_kpi
df = pd.read_csv('Sample_KPI_Data.csv')
result = forecast_kpi(df, 'TIME', 'RACH stp att', 7)
print(f'âœ“ Smoke test passed: {result.model_type}')
"

# 3. Log monitoring (ensure no errors)
tail -f logs/forecasting_module.log | grep ERROR
```

---

## NEXT STEPS

1. **Phase 4 Frontend Integration**: Integrate forecast results into Streamlit dashboard
2. **Phase 4 LLM Service**: Pass ForecastResult to Llama 70B for interpretation
3. **Phase 5 Optimization**: Scale to 1M+ rows, implement streaming
4. **Advanced Forecasting**: Add Prophet, LSTM, Transformer models as alternatives

---

## QUICK REFERENCE

### Common Commands

```bash
# Run tests
pytest test_forecasting_module.py -v

# Run specific test
pytest test_forecasting_module.py::TestFitArima::test_fit_arima_basic -v

# Run with coverage
pytest --cov=forecasting_module test_forecasting_module.py

# Format code
black forecasting_module.py

# Type check
mypy forecasting_module.py

# Lint
flake8 forecasting_module.py
```

### Key Functions Quick Reference

```python
# 1. Auto order selection
order = select_model_order(df, 'RACH stp att')

# 2. Simple ARIMA forecast
result = fit_arima(df, 'time', 'RACH stp att', 7)

# 3. ARIMAX with exogenous
result = fit_arimax(df, 'time', 'RACH stp att', 
                   ['RRC stp att', 'E-UTRAN avg RRC conn UEs'], 7)

# 4. High-level API (auto model selection)
result = forecast_kpi(df, 'time', 'RACH stp att', 7, 
                     exogenous_kpis=['RRC stp att'])

# 5. Batch forecasting
results = forecast_multiple_kpis(df, 'time', 
                                ['RACH stp att', 'RRC stp att'], 7)
```

---

**Version**: 1.0.0  
**Date**: 2025-12-03  
**Status**: Ready for Integration âœ…
